## **简介**

Hadoop自带一个称为HDFS的分布式文件系统，即Hadoop Distributed Filesystem，HDFS是以流式数据访问模式来存储超大文件，运行于商用硬件集群上。与正常文件系统不同的是，它会让集群中的每个机器仿佛访问同一个文件系统，即在A机器写入HDFS的文件，在B机器也能看到，在B机器删除HDFS文件，集群其他机器中的该文件也会被删除。

 

 

## **安装**

使用 Docker 快速搭建 Hadoop [集群环境](https://www.jianshu.com/p/b75f8bc9346d)

 

 

## **构成**

Hadoop的[核心](https://blog.csdn.net/jiangyu1013/article/details/72644098)就是HDFS和MapReduce，而两者只是理论基础，不是具体可使用的高级应用

### **HDFS特点**

1、**大数据文件**，非常适合上T级别的大文件或者一堆大数据文件的存储，如果文件只有几个G甚至更小就没啥意思了。

2、文件**分块存储**，HDFS会将一个完整的大文件平均分块存储到不同计算器上，它的意义在于读取文件时可以同时从多个主机取不同区块的文件，多主机读取比单主机读取效率要高得多得都。

3、**流式数据访问**，一次写入多次读写，这种模式跟传统文件不同，它不支持动态改变文件内容，而是要求让文件一次写入就不做变化，要变化也只能在文件末添加内容。

4、廉价硬件，HDFS可以应用在普通PC机上，这种机制能够让给一些公司用几十台廉价的计算机就可以撑起一个大数据集群。

5、硬件故障，HDFS认为所有计算机都可能会出问题，为了防止某个主机失效读取不到该主机的块文件，它将同一个文件块副本分配到其它某几个主机上，如果其中一台主机失效，可以迅速找另一块副本取文件。

### **HDFS元素**

1）**Block**：将一个文件进行分块，通常是64M。

2）**NameNode**：记录了文件是如何被拆分成block以及这些block都存储到了那些DateNode节点。保存整个文件系统的目录信息、文件信息及分块信息，这是由唯一 一台主机专门保存，当然这台主机如果出错，NameNode就失效了。在 Hadoop2.* 开始支持 activity-standy 模式----如果主 NameNode 失效，启动备用主机运行 NameNode。

3）**DataNode**：存储被拆分的blocks。分布在廉价的计算机上，用于存储Block块文件。

 



### **MapReduce**

我们要数图书馆中的所有书。你数1号书架，我数2号书架。这就是“Map”。我们人越多，数书就更快。

现在我们到一起，把所有人的统计数加在一起。这就是“Reduce”。

通俗说MapReduce是一套从海量源数据提取分析元素最后返回结果集的编程模型，将文件分布式存储到硬盘是第一步，而从海量数据中提取分析我们需要的内容就是MapReduce做的事了。

MapReduce的基本原理就是：将大的数据分析分成小块逐个分析，最后再将提取出来的数据汇总分析，最终获得我们想要的内容。当然怎么分块分析，怎么做Reduce操作非常复杂，Hadoop已经提供了数据分析的实现，我们只需要编写简单的需求命令即可达成我们想要的数据。

